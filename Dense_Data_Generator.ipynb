{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from icc.data_loaderB import ImageDataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting different window density sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.0015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'data/train/images'\n",
    "train_gt_path = 'data/train/ground_truth_csv'\n",
    "\n",
    "val_path = 'data/val/images'\n",
    "val_gt_path = 'data/val/ground_truth_csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = ImageDataLoader(train_path, \n",
    "                                    train_gt_path,\n",
    "                                    shuffle=False,\n",
    "                                    gt_downsample=False,\n",
    "                                    pre_load=False,\n",
    "                                    sr_mode=False)\n",
    "\n",
    "val_data_loader = ImageDataLoader(val_path, \n",
    "                                  val_gt_path,\n",
    "                                  shuffle=False,\n",
    "                                  gt_downsample=False,\n",
    "                                  pre_load=False,\n",
    "                                  sr_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dense_images(data_loader, stride = 3):\n",
    "\n",
    "    TD_Dict = {}\n",
    "    candidates = 0\n",
    "    selected = 0\n",
    "    \n",
    "    idx = 0\n",
    "    for blob in data_loader:\n",
    "\n",
    "        fname = blob['fname']\n",
    "        img = blob['data']\n",
    "        gt_density = blob['gt_density']\n",
    "        \n",
    "        h = img.shape[0]\n",
    "        w = img.shape[1]\n",
    "        \n",
    "        th = int(h/3.0 - ((h/3.0) % 4))\n",
    "        tw = int(w/3.0 - ((w/3.0) % 4))\n",
    "\n",
    "        th_small = th//4\n",
    "        tw_small = tw//4\n",
    "\n",
    "        density = gt_density.reshape((h, w))\n",
    "\n",
    "        area = th*tw\n",
    "        x = 0\n",
    "        idx = idx+1\n",
    "        \n",
    "        TD_Dict[fname] = []\n",
    "        while x < (h-th):\n",
    "            y = 0\n",
    "            while y < (w-tw):\n",
    "                den = round(np.sum(density[x:x+th, y:y+tw]).item(), 2) / area\n",
    "                if den > 0:\n",
    "                    candidates += 1\n",
    "                if den > threshold:\n",
    "                    selected += 1\n",
    "                    TD_Dict[fname].append([x, x+th, y, y+tw])\n",
    "                    \n",
    "                y += int(tw/stride)\n",
    "            x += int(th/stride)\n",
    "        \n",
    "        if (idx % 100 == 0) or (idx == data_loader.get_num_samples()):\n",
    "            print ('Processed ', idx, '/', data_loader.get_num_samples(), 'files')\n",
    "            \n",
    "    return TD_Dict, candidates, selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_TD_Dict, candidates, selected = extract_dense_images(train_data_loader)\n",
    "\n",
    "print(\"Selecting {}/{} based on threshold\".format(selected, candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Val_TD_Dict, candidates, selected = extract_dense_images(val_data_loader)\n",
    "\n",
    "print(\"Selecting {}/{} based on threshold\".format(selected, candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(file, data):\n",
    "    with open(file, 'wb') as f:\n",
    "        pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "save('data/train_dense_data.pkl', Train_TD_Dict)\n",
    "save('data/val_dense_data.pkl', Val_TD_Dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing data for thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_TD_List = [item for sublist in Train_TD_Dict.values() for item in sublist]\n",
    "Val_TD_List = [item for sublist in Val_TD_Dict.values() for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist(data, title, bins = 50):\n",
    "    plt.hist(data, bins)\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Total Density')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(Train_TD_List, 'Training Data Density histogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(Val_TD_List, 'Val Data Density histogram')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
