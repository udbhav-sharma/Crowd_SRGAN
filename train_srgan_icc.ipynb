{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import join, splitext\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import Compose, ToTensor, ToPILImage\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SRGAN Model Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from srgan.model import Generator, Discriminator\n",
    "from srgan.loss import GeneratorLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterative Crowd Counting Model Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icc.data_loaderB import ImageDataLoader\n",
    "from icc.model_ic_CNN import modelicCNN, retrain_icCNN\n",
    "from icc.evaluate_icCNN import evaluate_model\n",
    "from icc import network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU to run on\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing random seed\n",
    "rand_seed = 26700\n",
    "\n",
    "np.random.seed(rand_seed)\n",
    "torch.manual_seed(rand_seed)\n",
    "torch.cuda.manual_seed(rand_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters to tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "ALPHA = 2\n",
    "MAX_EPOCH = 200\n",
    "\n",
    "LR = 0.00001\n",
    "WEIGHT_DECAY = 0.00001\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "W = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataLoader Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'data/train/images'\n",
    "train_gt_path = 'data/train/ground_truth_csv'\n",
    "\n",
    "val_path = 'data/val/images'\n",
    "val_gt_path = 'data/val/ground_truth_csv'\n",
    "\n",
    "output_dir = 'logs/model_icCNN/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = ImageDataLoader(train_path, \n",
    "                                    train_gt_path,\n",
    "                                    shuffle=True,\n",
    "                                    gt_downsample=False,\n",
    "                                    pre_load=True,\n",
    "                                    sr_mode=True)\n",
    "\n",
    "val_data_loader = ImageDataLoader(val_path, \n",
    "                                  val_gt_path,\n",
    "                                  shuffle=False,\n",
    "                                  gt_downsample=False,\n",
    "                                  pre_load=False,\n",
    "                                  sr_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utils to read and transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomCrop(Input, Density, h, w, th, tw):\n",
    "    x1 = random.randint(0, h - th)\n",
    "    y1 = random.randint(0, w - tw)\n",
    "\n",
    "    Input = Input[x1:x1 + th, y1:y1 + tw]\n",
    "    Density = Density.reshape((h, w))[x1:x1 + th, y1:y1 + tw]\n",
    "\n",
    "    return Input, Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LowerResolution(img):\n",
    "    y, x = img.shape[0], img.shape[1]\n",
    "    fx, fy = int(x // ALPHA), int(y // ALPHA)\n",
    "    \n",
    "    img_small = cv2.resize(img, (fx, fy), interpolation=cv2.INTER_CUBIC)\n",
    "    lr_img = cv2.resize(img_small, (x, y), interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "    return lr_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_batch(blob):\n",
    "    img = blob['data']\n",
    "    gt_density = blob['gt_density']\n",
    "\n",
    "    h = img.shape[0]\n",
    "    w = img.shape[1]\n",
    "    \n",
    "    th = int(h/3.0 - ((h/3.0) % 4))\n",
    "    tw = int(w/3.0 - ((w/3.0) % 4))\n",
    "\n",
    "    Input_HR = torch.zeros(BATCH_SIZE, 3, th, tw)\n",
    "    Input_LR = torch.zeros(BATCH_SIZE, 3, th, tw)\n",
    "    GT_Density = torch.zeros(BATCH_SIZE, 1, th, tw)\n",
    "\n",
    "    for cur_step in range(0, BATCH_SIZE):\n",
    "        img_crop, gt_density_crop = RandomCrop(img, gt_density, h, w, th, tw)\n",
    "\n",
    "        lr_img = LowerResolution(img_crop)\n",
    "\n",
    "        Input_HR[cur_step] = ToTensor()(img_crop)\n",
    "        Input_LR[cur_step] = ToTensor()(lr_img)\n",
    "        GT_Density[cur_step] = torch.from_numpy(gt_density_crop)\n",
    "        \n",
    "    return Input_HR, Input_LR, GT_Density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing SRGAN parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing model\n",
    "netG = Generator()\n",
    "netD = Discriminator()\n",
    "\n",
    "network.weights_normal_init(netG)\n",
    "network.weights_normal_init(netD)\n",
    "\n",
    "netG.cuda()\n",
    "netD.cuda()\n",
    "\n",
    "netG.train()\n",
    "netD.train()\n",
    "\n",
    "# Initializing loss\n",
    "gen_criterion = GeneratorLoss()\n",
    "gen_criterion.cuda()\n",
    "\n",
    "# Initializing optimizer\n",
    "optimizerG = optim.Adam(netG.parameters())\n",
    "optimizerD = optim.Adam(netD.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing ICC parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing model\n",
    "net = modelicCNN()\n",
    "network.load_net('model_twoBranchSimple/best_icCNN.h5', net)\n",
    "net.cuda()\n",
    "net.train()\n",
    "\n",
    "# Initializing optimizer\n",
    "optimizerN = torch.optim.Adam(net.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# Initializing loss\n",
    "net_loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_maeHR = float('inf') #sys.maxint\n",
    "best_epochHR = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_Loss = []\n",
    "D_Loss = []\n",
    "N_Loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, MAX_EPOCH+1):\n",
    "\n",
    "    count = 0\n",
    "    g_epoch_loss = 0\n",
    "    d_epoch_loss = 0\n",
    "    n_epoch_loss = 0\n",
    "    \n",
    "    for blob in train_data_loader:\n",
    "        \n",
    "        optimizerN.zero_grad()\n",
    "        optimizerD.zero_grad()\n",
    "        optimizerG.zero_grad()\n",
    "\n",
    "        Input_HR, Input_LR, GT_Density = get_training_batch(blob)\n",
    "        \n",
    "        Input_HR = Input_HR.cuda()\n",
    "        Input_LR = Input_LR.cuda()\n",
    "        GT_Density = GT_Density.cuda()\n",
    "        \n",
    "        Input_SR = netG(Input_LR)\n",
    "        \n",
    "        # https://stackoverflow.com/questions/12201577/how-can-i-convert-an-rgb-image-into-grayscale-in-python\n",
    "        Input_SR_Gray = 255 * (0.299 * Input_SR[:,0,:,:] + 0.587 * Input_SR[:,1,:,:] + 0.114 * Input_SR[:,2,:,:])\n",
    "        Input_SR_Gray = Input_SR_Gray[:,None,:,:]\n",
    "        Input_SR_Gray = Input_SR_Gray.cuda()\n",
    "                    \n",
    "        Density = net(Input_SR_Gray)\n",
    "        \n",
    "        # Optimizing loss for icc net\n",
    "        LossHR = net_loss_fn(Density, GT_Density)\n",
    "        n_loss = 1000.0 * LossHR\n",
    "        n_loss.backward(retain_graph=True)\n",
    "        optimizerN.step()\n",
    "        \n",
    "        # Optimizing loss for Discriminator\n",
    "        real_out = netD(Input_HR).mean()\n",
    "        fake_out = netD(Input_SR).mean()\n",
    "        d_loss = 1 - real_out + fake_out\n",
    "        d_loss.backward(retain_graph=True)\n",
    "        optimizerD.step()\n",
    "\n",
    "        # Optimizing loss for Generator\n",
    "        g_loss = W * gen_criterion(fake_out, Input_SR, Input_HR) + n_loss\n",
    "        g_loss.backward()\n",
    "        optimizerG.step()\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "        print(\"Training epoch {}, Batch_Num {}/{}, G_Loss {}, D_Loss {}, N_Loss {}\".format(\n",
    "            epoch, count, train_data_loader.get_num_samples(), g_loss, d_loss, n_loss))\n",
    "        \n",
    "        g_epoch_loss += g_loss.data.item()\n",
    "        d_epoch_loss += d_loss.data.item()\n",
    "        n_epoch_loss += n_loss.data.item()\n",
    "        \n",
    "        del Input_HR, Input_LR, GT_Density, Density, real_out, fake_out, d_loss, g_loss\n",
    "        \n",
    "    G_Loss.append(g_epoch_loss/count)\n",
    "    D_Loss.append(d_epoch_loss/count)\n",
    "    N_Loss.append(n_epoch_loss/count)\n",
    "        \n",
    "    if (epoch % 5 == 0):\n",
    "        maeHR, mseHR = evaluate_model(net, netG, val_data_loader)\n",
    "        \n",
    "        net.train()\n",
    "        netG.train()\n",
    "        \n",
    "        if maeHR < best_maeHR:\n",
    "            best_maeHR = maeHR\n",
    "            best_mseHR = mseHR\n",
    "            \n",
    "            best_epochHR = epoch\n",
    "            \n",
    "            torch.save(netG, os.path.join(output_dir, 'best_generator.pth'))\n",
    "            network.save_net(os.path.join(output_dir, 'best_icCNN.h5'), net)\n",
    "\n",
    "        print(\"EPOCH: %d, MAE_HR: %.1f, MSE_HR: %0.1f\" % (epoch, maeHR, mseHR))\n",
    "        print(\"BEST MAE_HR: %0.1f, BEST MSE_HR: %0.1f, BEST Epoch: %4.2f\" % (best_maeHR, best_mseHR, best_epochHR))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(netG, os.path.join(output_dir, 'last_epoch_generator.pth'))\n",
    "network.save_net(os.path.join(output_dir, 'last_epoch_icCNN.h5'), net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(G_Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(D_Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(N_Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to output the Super Resolved images.\n",
    "\n",
    "# val_data_loader = ImageDataLoader(val_path, \n",
    "#                                   val_gt_path,\n",
    "#                                   shuffle=False,\n",
    "#                                   gt_downsample=False,\n",
    "#                                   pre_load=False,\n",
    "#                                   sr_mode=True)\n",
    "\n",
    "# model = torch.load(os.path.join(output_dir, 'netG.pth'))\n",
    "# model.cuda()\n",
    "\n",
    "# out_path = \"logs/SRGAN/val/\"\n",
    "\n",
    "# for blob in val_data_loader:\n",
    "#     img = blob['data']\n",
    "#     fname = blob['fname']\n",
    "    \n",
    "#     img = Variable(ToTensor()(img), requires_grad=False).unsqueeze(0)\n",
    "#     img = img.cuda()\n",
    "    \n",
    "#     out = model(img)\n",
    "#     out = ToPILImage()(out[0].data.cpu())\n",
    "    \n",
    "#     out.save(join(out_path, 'out_' + fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
